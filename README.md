# AI Privacy course

## Instrucciones

Una vez tienes un contexto general de algunas de las técnicas más relevantes para salvaguardar la privacidad y seguridad de la información en la creación y uso de LLMs, es tu turno de profundizar.

**Investiga sobre cualquiera de las técnicas presentadas en el apartado anterior, o incluso otras que puedan ser relevantes**:
- data privacy vaults
- de-identificación
- generación de datos sintéticos
- LLMs locales
- derechos de autor y copyright
- etc.


Puedes profundizar en los casos de uso en el contexto de LLMs, traer ejemplos textuales y visuales que te ayuden a entender el concepto, citar empresas y herramientas de referencia y/o curar contenido relevante.

Utiliza el asistente que prefieras para aprender sobre esta temática: ChatGPT, Microsoft Copilot, Gemini, Claude...

Eso sí, tendrás que **documentar lo aprendido en español en un formato tipo curso**, en este repositorio Github. 

En este caso el repositorio será colaborativo, iremos aceptando las pull requests para generar una base común. Una vez decidas la temática, *comienza por descargar la última versión del repositorio usando git pull y construye a partir de lo que tus compañer@s ya hayan dejado*. Si no sabes como mantenerte actualizado antes de publicar tu contenido y encontrarte con conflictos, pregunta en el grupo de Whatsapp o revisa documentación sobre git.

Te dejamos una semilla para que puedas comenzar, *introduciendo tu contenido en la categoría correspondiente y linkandolo en el Readme de la raiz, para tener una estructura más clara*. Si necesitas crear carpetas para nuevas categorías, añadir recursos gráficos, etc. hazlo, y no olvides actualizar el Readme de la raiz para que incluya el link a tu contenido. También documenta y cita las referencias bibliográficas y créditos adecuadamente. Si necesitas un ejemplo, puedes usar otros repositorios orientados a contenidos como [System Design Primer](https://github.com/donnemartin/system-design-primer)

Por último, no olvides añadir tu archivo de prompts en la carpeta prompts en formato prompts-tematica-iniciales.md, iniciando con un h1 con tu nombre y el tema. Por ejemplo:

prompts/prompts-enclavesseguros-DGZ.md

# Daniel González - Enclaves Seguros

Prompt:

```

Como un experto en ciberseguridad:

* describe que es el proceso de anonimización o de-identificación de datos para entrenamiento de LLMs.

* describe del proceso para anonimizar los datos

...

```

Este fichero será colaborativo.


Éxitos en tu investigación!



## Indice

- [Data privacy vaults](data-privacy-vaults/README.md)
- [Auditorías](auditorias/README.md)
  - [Ejemplo de auditoria](auditorias/ejemplo_auditoria_Anthropic.md)
- [De-identificación](de-identificacion/README.md)
  - [De-identificación de datos (por Mersad Meyfour Asadi)](tecnicas/de-identificacion/de-identificacion-MMA.md)
- [Generación de datos sintéticos](generacion_de_datos_sinteticos/README.md)
- [LLMs Locales - DFO](llms-locales-DFO/README.md)  
- [Filtros de Respuestas](filtros-de-respuestas/README.md)  
- [Red-Teaming y Simulación de Ataques](red-teaming/README.md)  
- [Jailbreaking](jailbreaking/README.md)  
- [Derechos de Autor](AI4Devs-Copyrights-&-Derechos-de-autor-MADV/README.md)
- [Generación de Datos Sintéticos](generacion_de_datos_sinteticos/README.md)
- [LLMs Locales](LLMs-locales/res/README.md)
- [LLMs Locales 2](llms-locales-DFO/README.md)
- [LLMs Locales 3](LLMs-LOCALES-TMS/LLMs-LOCALES/README.md)
- [Privacidad y Seguridad Proyectos](privacidad-seguridad-proyectos-tech/privacidad-seguridad-proyectos-tech.md)
